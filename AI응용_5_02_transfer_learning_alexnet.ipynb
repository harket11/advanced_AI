{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GqPX8IAM-kab",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# 운영 체제와 상호 작용하는 함수(예: 파일 경로 처리)를 제공하는 모듈을 불러옴.\n",
        "import os\n",
        "\n",
        "# 시간 관련 함수(예: 딜레이, 시간 측정)를 제공하는 모듈을 불러옴.\n",
        "import time\n",
        "\n",
        "# 객체를 깊은 복사(deep copy)하기 위한 모듈을 불러옴. 모델 가중치 복사 등에 유용함.\n",
        "import copy\n",
        "\n",
        "# NumPy 라이브러리를 np 별칭으로 불러옴. 배열 및 수치 연산에 사용함.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib의 pyplot 모듈을 plt 별칭으로 불러옴. 데이터 시각화에 사용함.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch 핵심 라이브러리를 불러옴. 딥러닝 모델 구축에 사용함.\n",
        "import torch\n",
        "\n",
        "# TorchVision 라이브러리를 불러옴. 비전 관련 데이터셋과 모델 등을 제공함.\n",
        "import torchvision\n",
        "\n",
        "# 신경망 레이어(nn) 모듈을 불러옴. 모델의 구성 요소를 정의함.\n",
        "import torch.nn as nn\n",
        "\n",
        "# 옵티마이저(optim) 모듈을 불러옴. 모델 학습 시 가중치 업데이트에 사용함.\n",
        "import torch.optim as optim\n",
        "\n",
        "# 학습률 스케줄러(lr_scheduler) 모듈을 불러옴. 학습 중에 학습률을 동적으로 조정함.\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# TorchVision에서 데이터셋, 미리 학습된 모델, 데이터 변환(transforms) 모듈을 불러옴.\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# PyTorch의 난수 생성기 시드(seed) 값을 0으로 설정했음. 결과의 재현성을 보장함.\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "id": "FIp72pUEAngv",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 업로드 창이 열립니다. 여기서 kaggle.json 파일을 선택하여 업로드합니다.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "s7GyAapZAo7S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/         # api key 인증 키 이동\n",
        "!chmod 600 ~/.kaggle/kaggle.json   # 파일접근 권한(본인만 읽고(4) 쓰기(2) 가능하게 권한위임)"
      ],
      "metadata": {
        "id": "ZGGQFpaoAyZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d ajayrana/hymenoptera-data #데이터 다운\n",
        "\n",
        "!unzip -q hymenoptera-data.zip -d . # 압축해제 (. : 현재 작업중인 디렉토)"
      ],
      "metadata": {
        "id": "VIVMW1ziBXT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 셋이 위치한 root directory 이름 정의\n",
        "ddir = 'hymenoptera_data'\n",
        "\n",
        "# 학습(train)과 검증(val) 데이터셋에 적용할 이미지 전처리(transform)를 dict() 정의\n",
        "data_transformers = {\n",
        "    'train': transforms.Compose([\n",
        "        # 데이터증강 (학습데이터만 적용)\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        # 이미지를 무작위로 자르고 크기를 224*224 조정\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # 이미지를 무작위 수평(좌우반전) 뒤집음\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "        # 파이토치 텐서로 변환\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221,0.230])]\n",
        "        # R,G,B 채널 별 평균과 표준편차 사용 >> 텐서를 정규화함\n",
        "    ),\n",
        "    'val': transforms.Compose([\n",
        "        # 데이터증강 (학습데이터만 적용)\n",
        "        transforms.Resize(256),\n",
        "        # 이미지를 256*256 조정\n",
        "        transforms.CenterCrop(224),\n",
        "        # 이미지 중앙을 224*224 크기로 자름\n",
        "\n",
        "        transforms.ToTensor(),\n",
        "        # 파이토치 텐서로 변환\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221,0.230])]\n",
        "        # R,G,B 채널 별 평균과 표준편차 사용 >> 텐서를 정규화함\n",
        "    )\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "eHTux71QCQ6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'train'과 'val' 디렉토리에서 ImageFolder 데이터셋을 로드할게요\n",
        "# 각 폴더 이름(클래스)과 이미지 매핑 >> 해당하는 전처리 적용\n",
        "\n",
        "{k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in {'train', 'val'}}"
      ],
      "metadata": {
        "id": "nsCRKj3YHesL",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True, num_workers=2)\n",
        "#                    for k in {'train', 'val'}}\n",
        "\n",
        "# {'train': torch.utils.data.DataLoader(img_data['train'], batch_size=8, shuffle=True, num_workers=2),\n",
        "#              'val': torch.utils.data.DataLoader(img_data['val'], batch_size=8, shuffle=False, num_workers=2)}\n",
        "# torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "O18syPtgKwjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in {'train', 'val'}}\n",
        "\n",
        "# ImageFolder 데이터 셋 활용, DataLoader 객체 생성\n",
        "# batch_size = 8. 데이터 섞기 shuffle 활성화, 작업자 수(num_workers = 2) 설정\n",
        "\n",
        "# dloaders = {k: torch.utils.data.DataLoader(img_data[k], batch_size=8, shuffle=True, num_workers=2)\n",
        "#                    for k in {'train', 'val'}}\n",
        "# 이러면 validation 도 데이터가 섞이는데요? by m.j.k\n",
        "\n",
        "dloaders = {'train': torch.utils.data.DataLoader(img_data['train'], batch_size=8, shuffle=True, num_workers=2),\n",
        "             'val': torch.utils.data.DataLoader(img_data['val'], batch_size=8, shuffle=False, num_workers=2)}\n",
        "\n",
        "# 학습 및 검증 데이터셋 전체 이미지 개수(사이즈) 저장함\n",
        "dset_sizes = {x: len(img_data[x]) for x in {'train', 'val'}}\n",
        "\n",
        "# 데이터셋에서 자동으로 추출된 클래스 이름 리스트로 저장\n",
        "classes = img_data['train'].classes\n",
        "\n",
        "# 학습에 사용할 장치(device)를 설정함.\n",
        "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "LllHRuUEIiwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지를 화면에 표시하는 함수 정의 (정규화된 이미지를 역변환함)\n",
        "\n",
        "def imageshow(img, text=None):\n",
        "   img = img.numpy().transpose((1,2,0))\n",
        "   # torch tensor data를 numpy 배열로 변환\n",
        "   # tensor (chw : 채널, 높이, 너비) >> (높이, 너비, 채널) 전치함.\n",
        "\n",
        "   # 정규화에 사용했던 R,G,B 채널별 평균(mean) 정의\n",
        "   avg = np.array([0.490,0.449,0.411])\n",
        "\n",
        "   # 정규화에 사용했던 R,G,B 채널별 표준편차(stddev) 정의\n",
        "   stddev = np.array([0.231,0.221,0.230])\n",
        "\n",
        "   # 역정규화 (denormalization) 수행 : img =  stddev * img + avg\n",
        "   img =  stddev * img + avg\n",
        "\n",
        "   # 픽셀 값이 [0,1] 범위를 벗어나는 생길 경우 대비 >> 해당 범위 내로 clip 함\n",
        "   img = np.clip(img, 0,1)\n",
        "\n",
        "   plt.imshow(img) # 이미지 표시\n",
        "   plt.axis('off')\n",
        "\n",
        "   # 텍스트(제목) 제공되는 경우, 이미지 제목으로 설정하고 싶어\n",
        "   if text is not None:\n",
        "      plt.title(text)"
      ],
      "metadata": {
        "id": "IGU-y0aQImd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습 데이터로더('train') 이터레이터, 넥스트 가져옴\n",
        "d_iter = iter(dloaders['train'])\n",
        "\n",
        "# 이터레이터에서 다음 미니배치(이미지 텐서와 클래스 레이블) 가져옴\n",
        "imgs, cls = next(d_iter)\n",
        "\n",
        "# 미니 배치 이미지들을 하나의 격자(grid) 이미지로 만들어 표현\n",
        "grid = torchvision.utils.make_grid(imgs)\n",
        "\n",
        "# 격자 이미지와 해당 레이블(cls) 제목 설정 >> 화면에 표시\n",
        "imageshow(grid, text=[classes[x] for x in cls])"
      ],
      "metadata": {
        "id": "apVntFokRaYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 전이학습(transfer learning) 함수 정의\n",
        "def finetune_model(pretrained_model, loss_func, optim, epochs=10):\n",
        "  # 학습시간 기록\n",
        "  start = time.time()\n",
        "\n",
        "  # 현재 모델의 가중치(state_dict)를 깊은 복사 > 초기상태 저장\n",
        "  model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
        "\n",
        "  # 검증 정확도 추적을 위한 변수를 0.0 초기화\n",
        "  accuracy = 0.0\n",
        "\n",
        "  # 지정된 epochs 수 만큼 반복하여 학습을 진행함.\n",
        "  for e in range(epochs):\n",
        "    # 현재 에폭 진행 상황 출력\n",
        "    print(f'epoch_number {e} / {epochs-1}')\n",
        "    print('='*20)\n",
        "\n",
        "    # 현재 에폭 내에서 학습 데이터 셋과 검증 데이터 셋 순환\n",
        "    for dset in ['train', 'val']:\n",
        "      if dset == 'train':\n",
        "        pretrained_model.train()\n",
        "        # 모델을 학습 모드로 설정(예: Dropout, BatchNorm 활성화)\n",
        "\n",
        "      else:\n",
        "        pretrained_model.eval()\n",
        "        # 평가 모드 (예: Dropout, BatchNorm 비활성화)(**)\n",
        "\n",
        "      # 에폭 별 손실과 성공횟수 0.0 초기화\n",
        "      loss = 0.0\n",
        "      successes = 0\n",
        "\n",
        "      # 학습 또는 검증 데이터 로더 순회\n",
        "      for imgs, tgts in dloaders[dset]:\n",
        "          # 입력 이미지, 정답 레이블 >> 설정된 device로 이동\n",
        "          imgs = imgs.to(dvc)\n",
        "          tgts = tgts.to(dvc)\n",
        "\n",
        "          optim.zero_grad()\n",
        "\n",
        "          # 학습 모드('train') 에서만 gradient 변화도 계산을 활성화함\n",
        "          with torch.set_grad_enabled(dset == 'train'):\n",
        "              ops = pretrained_model(imgs)\n",
        "              # 순전파 수행, 예측 결과(ops)얻음\n",
        "              _, preds = torch.max(ops, 1)\n",
        "              # 예측 결과에서 모델이 예측한 클래스(preds) 찾음(최대값이 있던 위치 indices)\n",
        "              # _ : 최대값(value) : 우리 안 쓸거야(필요없어)\n",
        "              loss_curr = loss_func(ops, tgts)\n",
        "              # 현재 미니배치에 대한 손실 계산\n",
        "\n",
        "              # 학습 모드('train')인 경우에만 역전파, 가중치 업데이트 수행함\n",
        "              if dset == 'train':\n",
        "                loss_curr.backward()\n",
        "                optim.step()\n",
        "\n",
        "          # 배치 손실을 전체 에폭 손실에 누적\n",
        "          # >> 이미지 개수를 곱해서 평균 손실이 아닌 총 손실을 누적함\n",
        "          loss += loss_curr.item() * imgs.size(0)\n",
        "          # loss_curr : 현재 미니배치의 평균 loss 값\n",
        "          # .item() >> 파이선 숫자(float)\n",
        "          # imgs.size(0) : batch_size (현재 배치 내 이미지 개)\n",
        "\n",
        "          # 예측과 정답과 일치하는 개수 세어서 성공 횟수를 누적함\n",
        "          successes += torch.sum(preds == tgts.data)\n",
        "\n",
        "      # 에폭이 끝난 후, 전체 손실을 데이터 셋 나누어서 평균 에폭 손실 계산\n",
        "      loss_epoch = loss / dset_sizes[dset]\n",
        "      # dset_sizes[dset] 데이터 셋(dset)의 전체 크기(총 샘풀 수)\n",
        "      # 전체 성공횟수를 데이터 셋 나누어서 에폭 정확도를 계산함\n",
        "      accuracy_epoch = successes.double() / dset_sizes[dset]\n",
        "      # .double() 텐서의 데이터 타입을 부동소수점\n",
        "\n",
        "      print(f'{dset} loss in this epoch: {loss_epoch}, accuracy in this epoch: {accuracy_epoch}')\n",
        "\n",
        "      # 현재 검증 정확도가 지금까지 최고 정확도 보다 높으면\n",
        "      if dset == 'val' and accuracy_epoch > accuracy:\n",
        "          accuracy = accuracy_epoch\n",
        "          model_weights = copy.deepcopy(pretrained_model.state_dict())\n",
        "      print()\n",
        "\n",
        "  # 학습 종료시간 계산 >> 총 소요시간 출력\n",
        "  time_delta = time.time() - start\n",
        "  print(f'Training fished in {time_delta // 60}mins {time_delta % 60}secs')\n",
        "  print(f'Best accuracy: {accuracy}')\n",
        "\n",
        "  # 최고 성능 보였던 시점의 모델 가중치(model_weights) 를 모델에 로드함\n",
        "  pretrained_model.load_state_dict(model_weights)\n",
        "\n",
        "  return pretrained_model"
      ],
      "metadata": {
        "id": "dxe2cTSBTT5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델의 예측결과 시각화 하는 함수 정의\n",
        "# pretrained_model : 사전학습된 모델, max_num_imgs : 표시할 최대 이미지 수 입력받음\n",
        "\n",
        "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
        "    torch.manual_seed(1) # 난수 생성기 seed 설정\n",
        "\n",
        "    # 모델의 원래 학습 모드 상태 (True/False) 저장\n",
        "    was_model_training = pretrained_model.training\n",
        "    # 모델이 현재 train() 상태인지 eval() 상태인지 기록\n",
        "    # >> 함수 종료된 뒤에 원래 상태로 복구하기 위해서\n",
        "\n",
        "    # 모델을 평가 모드로 설정\n",
        "    pretrained_model.eval()\n",
        "\n",
        "    # 시각화할 이미지 카운터 0으로 초기화\n",
        "    imgs_counter = 0\n",
        "\n",
        "    # 그림 객체 생성\n",
        "    fig = plt.figure()\n",
        "\n",
        "    # gradient 계산 비 활성화\n",
        "    with torch.no_grad():\n",
        "      # 검증 데이터 로더('val') 순회\n",
        "      for i, (imgs, tgts) in enumerate(dloaders['val']):\n",
        "        # 입력 이미지, 정답 레이블 >> 설정된 device로 이동\n",
        "        imgs = imgs.to(dvc)\n",
        "        tgts = tgts.to(dvc)\n",
        "\n",
        "        ops = pretrained_model(imgs)\n",
        "        _, preds = torch.max(ops,1)\n",
        "\n",
        "        # 현재 배치 내에서 모든 이미지에 대해 순회\n",
        "        for j in range(imgs.size()[0]):\n",
        "          imgs_counter += 1\n",
        "\n",
        "          ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
        "          # (default) max_num_imgs=4 >> (2,2)\n",
        "          ax.axis('off')\n",
        "\n",
        "          ax.set_title(f'pred: {classes[preds[j]]} || target: {classes[tgts[j]]}')\n",
        "\n",
        "          # 역정규화된 이미지를 화면에 표시\n",
        "          imageshow(imgs.cpu().data[j])\n",
        "\n",
        "          # 설정된 최대 이미지 수에 도달한다면\n",
        "          if imgs_counter == max_num_imgs:\n",
        "             pretrained_model.train(mode=was_model_training)\n",
        "             #  모델의 모드를 원래 상태로 되돌려라\n",
        "             return\n",
        "             # 함수 실행 종료\n",
        "      pretrained_model.train(mode=was_model_training)\n",
        "      #  loop를 끝까지 실행했다면 모델의 모드를 원래 상태로 돌려놓아요"
      ],
      "metadata": {
        "id": "0oMSsAMesG7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torchvision.models 에서 alexnet 모델 불러옴\n",
        "# pretrained=True 설정 ImageNet 데이터셋으로 미리 학습된 가중치 로드함\n",
        "\n",
        "model_finetuned = models.alexnet(pretrained=True) # deprecated soon (chagned to 'weights')\n",
        "\n",
        "# 로드된 alexnet 모델의 특징추출기(Convolution layer) 부분인 feature 모듈의 구조 출력\n",
        "print(model_finetuned.features)"
      ],
      "metadata": {
        "id": "6gmts0uPy1Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_finetuned.classifier)"
      ],
      "metadata": {
        "id": "eOOXvW28zSqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_finetuned = models.alexnet(pretrained=True)\n",
        "# 기존 1,000개 클래스 >> 현재 데이터 셋 클래스 개수(2개, 벌/개미) 변경\n",
        "# 기존 분류기 마지막 레이어 classifier[6] (인덱스 6) 수정\n",
        "model_finetuned.classifier[6] = nn.Linear(4096, 2)"
      ],
      "metadata": {
        "id": "KN5gRFfk5CqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 손실함수 cross entropy 정의\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer 정의\n",
        "optim_finetune = optim.SGD(model_finetuned.parameters(), lr=0.0001)\n",
        "\n",
        "model_finetuned = model_finetuned.to(dvc)\n",
        "\n",
        "model_finetune = finetune_model(model_finetuned, loss_func, optim_finetune)\n",
        "model_finetune"
      ],
      "metadata": {
        "id": "BS2t0QJY1SGp",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_predictions(model_finetune)"
      ],
      "metadata": {
        "id": "E0K63CHm2TCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# eos"
      ],
      "metadata": {
        "id": "mXVM9BOX35og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehoN4OEB87Sz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}