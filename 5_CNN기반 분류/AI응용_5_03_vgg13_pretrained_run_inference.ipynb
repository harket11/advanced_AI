{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hTCBce8UjbBB"
      },
      "outputs": [],
      "source": [
        "# 운영 체제와 상호 작용하는 함수(예: 파일 처리)를 불러옴.\n",
        "import os\n",
        "\n",
        "# 시간 관련 함수(예: 시간 측정)를 불러옴.\n",
        "import time\n",
        "\n",
        "# 객체를 깊은 복사(deep copy)하기 위한 모듈을 불러옴.\n",
        "import copy\n",
        "\n",
        "# NumPy 라이브러리를 np 별칭으로 불러옴. 배열 및 수치 연산에 사용함.\n",
        "import numpy as np\n",
        "\n",
        "# Matplotlib의 pyplot 모듈을 plt 별칭으로 불러옴. 데이터 시각화에 사용함.\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch 핵심 라이브러리를 불러옴.\n",
        "import torch\n",
        "\n",
        "# TorchVision 라이브러리를 불러옴.\n",
        "import torchvision\n",
        "\n",
        "# 신경망 레이어(nn) 모듈을 불러옴.\n",
        "import torch.nn as nn\n",
        "\n",
        "# 옵티마이저(optim) 모듈을 불러옴.\n",
        "import torch.optim as optim\n",
        "\n",
        "# 학습률 스케줄러(lr_scheduler) 모듈을 불러옴. 학습률 조정에 사용함.\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "# TorchVision에서 데이터셋, 미리 학습된 모델, 데이터 변환 모듈을 불러옴.\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "# PyTorch의 난수 생성기 시드(seed) 값을 0으로 설정했음. 재현성을 보장함.\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 파일 업로드 창이 열립니다. 여기서 kaggle.json 파일을 선택하여 업로드합니다.\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "jHXNcsZengBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d ajayrana/hymenoptera-data\n",
        "!unzip -q hymenoptera-data.zip -d ."
      ],
      "metadata": {
        "id": "T0EmEGwXjsqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzW0I5EXjbBC"
      },
      "outputs": [],
      "source": [
        "ddir = 'hymenoptera_data'\n",
        "\n",
        "# 학습(train)과 검증(val) 데이터셋에 적용할 이미지 전처리(transform)를 딕셔너리로 정의함.\n",
        "data_transformers = {\n",
        "    # 학습 데이터 변환: 데이터 증강(Augmentation) 포함함.\n",
        "    'train': transforms.Compose([\n",
        "        # 이미지를 무작위로 자르고 224x224로 조절함.\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        # 이미지를 무작위로 수평 뒤집음.\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        # 이미지를 PyTorch 텐서로 변환함.\n",
        "        transforms.ToTensor(),\n",
        "        # 텐서를 채널별 평균과 표준편차를 사용하여 정규화함.\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
        "    ]),\n",
        "    # 검증 데이터 변환: 크기 조정과 정규화만 포함함.\n",
        "    'val': transforms.Compose([\n",
        "        # 이미지를 256 크기로 조절함.\n",
        "        transforms.Resize(256),\n",
        "        # 이미지 중앙을 224x224 크기로 자름.\n",
        "        transforms.CenterCrop(224),\n",
        "        # 이미지를 PyTorch 텐서로 변환함.\n",
        "        transforms.ToTensor(),\n",
        "        # 학습 데이터와 동일하게 정규화를 적용함.\n",
        "        transforms.Normalize([0.490, 0.449, 0.411], [0.231, 0.221, 0.230])\n",
        "    ])}\n",
        "\n",
        "# 'train'과 'val' 디렉토리에서 ImageFolder 데이터셋을 로드하고 해당 전처리를 적용함.\n",
        "img_data = {k: datasets.ImageFolder(os.path.join(ddir, k), data_transformers[k]) for k in ['train', 'val']}\n",
        "\n",
        "# ImageFolder 데이터셋을 DataLoader 객체로 변환함.\n",
        "# 배치 크기 8, 데이터 섞기(shuffle) 활성화, 작업자 수(num_workers)는 2로 설정함.\n",
        "dloaders = {'train': torch.utils.data.DataLoader(img_data['train'], batch_size=8, shuffle=True, num_workers=2),\n",
        "             'val': torch.utils.data.DataLoader(img_data['val'], batch_size=8, shuffle=False, num_workers=2)}\n",
        "\n",
        "# 학습 및 검증 데이터셋 전체 이미지 개수(사이즈) 저장함\n",
        "dset_sizes = {x: len(img_data[x]) for x in {'train', 'val'}}\n",
        "\n",
        "# 데이터셋에서 자동으로 추출된 클래스 이름 리스트로 저장\n",
        "classes = img_data['train'].classes\n",
        "\n",
        "# 학습에 사용할 장치(device)를 설정함.\n",
        "dvc = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Tkg3NDTjbBC"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "with open('/imagenet1000_clsidx_to_labels.txt') as f:\n",
        "    classes_data = f.read()\n",
        "classes_dict = ast.literal_eval(classes_data)\n",
        "print({k: classes_dict[k] for k in list(classes_dict)[:5]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4pIB6UFjbBD"
      },
      "outputs": [],
      "source": [
        "# 이미지를 화면에 표시하는 함수를 정의함. (정규화된 이미지를 역변환함)\n",
        "def imageshow(img, text=None):\n",
        "    # PyTorch 텐서를 NumPy 배열로 변환하고 채널 순서를 Matplotlib 형식으로 전치함.\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "\n",
        "    # 정규화에 사용했던 R, G, B 채널별 평균(mean)을 정의함.\n",
        "    avg = np.array([0.490, 0.449, 0.411])\n",
        "\n",
        "    # 정규화에 사용했던 R, G, B 채널별 표준편차(stddev)를 정의함.\n",
        "    stddev = np.array([0.231, 0.221, 0.230])\n",
        "\n",
        "    # 역정규화(denormalization)를 수행함.\n",
        "    img = stddev * img + avg\n",
        "\n",
        "    # 픽셀 값을 [0, 1] 범위 내로 클립(clip)함.\n",
        "    img = np.clip(img, 0, 1)\n",
        "\n",
        "    # Matplotlib을 사용하여 이미지를 화면에 표시함.\n",
        "    plt.imshow(img)\n",
        "\n",
        "    # 텍스트가 제공된 경우 이미지의 제목으로 설정함.\n",
        "    if text is not None:\n",
        "        plt.title(text)\n",
        "\n",
        "# 학습된 모델의 예측 결과를 시각화하는 함수를 정의함.\n",
        "def visualize_predictions(pretrained_model, max_num_imgs=4):\n",
        "    # 난수 생성기 시드를 설정했음.\n",
        "    torch.manual_seed(1)\n",
        "\n",
        "    # 모델의 원래 학습 모드 상태를 저장함.\n",
        "    was_model_training = pretrained_model.training\n",
        "\n",
        "    # 모델을 평가 모드로 설정함.\n",
        "    pretrained_model.eval()\n",
        "\n",
        "    # 시각화할 이미지 카운터를 0으로 초기화함.\n",
        "    imgs_counter = 0\n",
        "\n",
        "    # Matplotlib 그림 객체(figure)를 생성함.\n",
        "    fig = plt.figure()\n",
        "\n",
        "    # 변화도(gradient) 계산을 비활성화함.\n",
        "    with torch.no_grad():\n",
        "        # 검증 데이터 로더('val')를 순회함.\n",
        "        for i, (imgs, tgts) in enumerate(dloaders['val']):\n",
        "            # 이미지와 정답 레이블을 장치(GPU/CPU)로 이동시킴. (이 부분에서 tgts가 사용되지 않고 있음)\n",
        "            imgs = imgs.to(dvc)\n",
        "            # tgts = tgts.to(dvc) # 주석: tgts는 현재 사용되지 않으나, GPU로 이동시키는 것이 일반적임.\n",
        "\n",
        "            # 순전파를 수행하여 예측 결과(ops)를 얻음.\n",
        "            ops = pretrained_model(imgs)\n",
        "\n",
        "            # 예측 결과에서 예측 클래스(preds)를 찾음.\n",
        "            _, preds = torch.max(ops, 1)\n",
        "\n",
        "            # 현재 배치 내의 모든 이미지에 대해 순회함.\n",
        "            for j in range(imgs.size()[0]):\n",
        "                # 이미지 카운터를 증가시킴.\n",
        "                imgs_counter += 1\n",
        "\n",
        "                # 서브플롯 위치를 설정함.\n",
        "                ax = plt.subplot(max_num_imgs//2, 2, imgs_counter)\n",
        "\n",
        "                # 축(axis) 표시를 끔.\n",
        "                ax.axis('off')\n",
        "\n",
        "                # 예측 클래스 이름만 제목으로 설정함. (원래 정답 레이블(target)도 포함했으나 지금은 예측만 표시함)\n",
        "                # classes_dict는 이전에 정의된 classes 변수와 동일할 것으로 예상함.\n",
        "                ax.set_title(f'pred: {classes_dict[int(preds[j])]}')\n",
        "\n",
        "                # 역정규화된 이미지를 화면에 표시함.\n",
        "                imageshow(imgs.cpu().data[j])\n",
        "\n",
        "                # 설정된 최대 이미지 수에 도달했다면\n",
        "                if imgs_counter == max_num_imgs:\n",
        "                    # 모델의 모드를 원래 상태로 되돌림.\n",
        "                    pretrained_model.train(mode=was_model_training)\n",
        "                    # 함수 실행을 종료함.\n",
        "                    return\n",
        "        # 루프를 끝까지 실행했다면 모델의 모드를 원래 상태로 되돌림.\n",
        "        pretrained_model.train(mode=was_model_training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "e2D6FD4rjbBD"
      },
      "outputs": [],
      "source": [
        "model = models.vgg13(pretrained=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zze_4UWvjbBD"
      },
      "outputs": [],
      "source": [
        "visualize_predictions(model)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}